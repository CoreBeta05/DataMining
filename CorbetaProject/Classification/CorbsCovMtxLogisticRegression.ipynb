{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae434e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50671e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "0   63    1       typical     145   233    1        2    150      0      2.3   \n",
       "1   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
       "2   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
       "3   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
       "4   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "0      3  0.0       fixed   No  \n",
       "1      2  3.0      normal  Yes  \n",
       "2      2  2.0  reversable  Yes  \n",
       "3      3  0.0      normal   No  \n",
       "4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CMLR\n",
    "df = pd.read_csv('D:\\\\CS 325 Data Mining\\\\Datasets\\\\archive\\\\Heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c4da47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Generate some synthetic data\n",
    "X, y = make_classification(n_samples=100, n_features=4, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute the class means\n",
    "class_means = np.mean(X_train, axis=0)\n",
    "\n",
    "# Compute the within-class scatter matrix\n",
    "S_w = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for label in np.unique(y_train):\n",
    "    X_c = X_train[y_train == label]\n",
    "    class_mean = np.mean(X_c, axis=0)\n",
    "    centered_data = X_c - class_mean\n",
    "    scatter_matrix = np.dot(centered_data.T, centered_data)\n",
    "    S_w += scatter_matrix\n",
    "\n",
    "# Compute the between-class scatter matrix\n",
    "S_b = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for label in np.unique(y_train):\n",
    "    n = X_train[y_train == label].shape[0]\n",
    "    class_mean_diff = class_means - np.mean(X_train[y_train == label], axis=0)\n",
    "    S_b += n * np.outer(class_mean_diff, class_mean_diff)\n",
    "\n",
    "# Compute the inverse of S_w\n",
    "S_w_inv = np.linalg.inv(S_w)\n",
    "\n",
    "# Compute the weight matrix W\n",
    "W = np.dot(S_w_inv, class_means)\n",
    "\n",
    "# Project the training data onto the LDA subspace\n",
    "X_train_lda = np.dot(X_train, W)\n",
    "\n",
    "# Add a column of ones to account for the bias term\n",
    "X_train_lda = np.column_stack((np.ones(X_train_lda.shape[0]), X_train_lda))\n",
    "\n",
    "# Fit logistic regression model\n",
    "lr_weights = np.dot(np.linalg.inv(np.dot(X_train_lda.T, X_train_lda)), np.dot(X_train_lda.T, y_train))\n",
    "\n",
    "# Project the test data onto the LDA subspace\n",
    "X_test_lda = np.dot(X_test, W)\n",
    "\n",
    "# Add a column of ones to account for the bias term\n",
    "X_test_lda = np.column_stack((np.ones(X_test_lda.shape[0]), X_test_lda))\n",
    "\n",
    "# Predict the test data labels\n",
    "y_pred = np.round(1 / (1 + np.exp(-np.dot(X_test_lda, lr_weights))))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7d722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 2  6]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Generate some synthetic data\n",
    "X, y = make_classification(n_samples=100, n_features=4, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute the class means\n",
    "class_means = np.mean(X_train, axis=0)\n",
    "\n",
    "# Compute the within-class scatter matrix\n",
    "S_w = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for label in np.unique(y_train):\n",
    "    X_c = X_train[y_train == label]\n",
    "    class_mean = np.mean(X_c, axis=0)\n",
    "    centered_data = X_c - class_mean\n",
    "    scatter_matrix = np.dot(centered_data.T, centered_data)\n",
    "    S_w += scatter_matrix\n",
    "\n",
    "# Compute the between-class scatter matrix\n",
    "S_b = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "for label in np.unique(y_train):\n",
    "    n = X_train[y_train == label].shape[0]\n",
    "    class_mean_diff = class_means - np.mean(X_train[y_train == label], axis=0)\n",
    "    S_b += n * np.outer(class_mean_diff, class_mean_diff)\n",
    "\n",
    "# Compute the inverse of S_w\n",
    "S_w_inv = np.linalg.inv(S_w)\n",
    "\n",
    "# Compute the weight matrix W\n",
    "W = np.dot(S_w_inv, class_means)\n",
    "\n",
    "# Project the training data onto the LDA subspace\n",
    "X_train_lda = np.dot(X_train, W)\n",
    "\n",
    "# Add a column of ones to account for the bias term\n",
    "X_train_lda = np.column_stack((np.ones(X_train_lda.shape[0]), X_train_lda))\n",
    "\n",
    "# Fit logistic regression model\n",
    "lr_weights = np.dot(np.linalg.inv(np.dot(X_train_lda.T, X_train_lda)), np.dot(X_train_lda.T, y_train))\n",
    "\n",
    "# Project the test data onto the LDA subspace\n",
    "X_test_lda = np.dot(X_test, W)\n",
    "\n",
    "# Add a column of ones to account for the bias term\n",
    "X_test_lda = np.column_stack((np.ones(X_test_lda.shape[0]), X_test_lda))\n",
    "\n",
    "# Predict the test data labels\n",
    "y_pred = np.round(1 / (1 + np.exp(-np.dot(X_test_lda, lr_weights))))\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bed8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
